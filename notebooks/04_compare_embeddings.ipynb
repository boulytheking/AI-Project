{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-24T18:39:20.437054Z",
     "start_time": "2025-05-24T18:39:20.304106Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) Charge les deux jeux\n",
    "df_human = pd.read_csv(\"../data/train_essays.csv\")          # label 0\n",
    "df_ai    = pd.read_csv(\"../data/generated_ai_essays.csv\")   # label 1\n",
    "\n",
    "# 2) Concatène\n",
    "df_full = pd.concat([df_human, df_ai], ignore_index=True)\n",
    "\n",
    "# 3) Nettoie les valeurs manquantes\n",
    "df_full[\"text\"] = (\n",
    "    df_full[\"text\"]\n",
    "        .fillna(\"\")          # NaN  -> \"\"\n",
    "        .replace(\"null\", \"\") # 'null' -> \"\"\n",
    ")\n",
    "\n",
    "print(\"Total textes :\", len(df_full), \"| IA :\", df_full[\"generated\"].sum())\n",
    "\n",
    "# 4) Sauvegarde pour le preprocess en CLI\n",
    "df_full.to_csv(\"../data/combined_essays.csv\", index=False)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total textes : 1428 | IA : 53\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T18:39:38.293759Z",
     "start_time": "2025-05-24T18:39:35.809023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd, numpy as np\n",
    "\n",
    "# Recharge le CSV combiné\n",
    "df = pd.read_csv(\"../data/combined_essays.csv\")\n",
    "\n",
    "# Si tu n’as pas ajouté la colonne text_pp dans le preprocess, fais un clean rapide :\n",
    "from src.preprocess import clean_text\n",
    "df[\"text_pp\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "y      = df[\"generated\"].values          # labels 0 / 1\n",
    "texts  = df[\"text_pp\"].tolist()          # liste de chaînes\n"
   ],
   "id": "6aaa14c2e2a91ee7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamleroy/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T18:47:26.948206Z",
     "start_time": "2025-05-24T18:47:05.655505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EMBEDDINGS = {\n",
    "    \"tfidf\":  None,\n",
    "    \"minilm\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    #  word2vec / doc2vec / glove seront ajoutés ensuite\n",
    "}\n",
    "\n",
    "for name, spec in EMBEDDINGS.items():\n",
    "    print(f\"\\n========== {name.upper()} ==========\")\n",
    "\n",
    "    # -------- A. Encodage --------\n",
    "    if name == \"tfidf\":\n",
    "        from joblib import load\n",
    "        vectorizer = load(\"../outputs/full/tfidf_vectorizer.pkl\")\n",
    "        X = vectorizer.transform(texts)\n",
    "\n",
    "    elif name == \"minilm\":\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "        model = SentenceTransformer(spec)\n",
    "        X = model.encode(texts, batch_size=128, show_progress_bar=True)\n",
    "\n",
    "    # (placeholders pour les autres embeddings)\n",
    "    else:\n",
    "        print(\">>> À implémenter dans la prochaine étape\")\n",
    "        continue\n",
    "\n",
    "    # -------- B. Split, entraînement, rapport --------\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    clf = LogisticRegression(max_iter=10_000, n_jobs=-1)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    y_pred = clf.predict(X_val)\n",
    "\n",
    "    print(classification_report(y_val, y_pred, digits=3))\n"
   ],
   "id": "e780f0c0b97d892f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== TFIDF ==========\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     1.000     0.993       275\n",
      "           1      1.000     0.636     0.778        11\n",
      "\n",
      "    accuracy                          0.986       286\n",
      "   macro avg      0.993     0.818     0.885       286\n",
      "weighted avg      0.986     0.986     0.985       286\n",
      "\n",
      "\n",
      "========== MINILM ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/williamleroy/PycharmProjects/PythonProject/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Batches: 100%|██████████| 12/12 [00:13<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       275\n",
      "           1      1.000     1.000     1.000        11\n",
      "\n",
      "    accuracy                          1.000       286\n",
      "   macro avg      1.000     1.000     1.000       286\n",
      "weighted avg      1.000     1.000     1.000       286\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T17:07:36.022946Z",
     "start_time": "2025-05-25T14:04:26.195972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "EMBEDDINGS = {\n",
    "    \"tfidf\":  None,\n",
    "    \"minilm\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    \"word2vec\": \"word2vec\",          # entraînement local\n",
    "    \"doc2vec\": \"doc2vec\",            # entraînement local\n",
    "    \"glove\":   \"glove-wiki-gigaword-100\"  # pré-entraîné\n",
    "}\n",
    "\n",
    "\n",
    "for name, spec in EMBEDDINGS.items():\n",
    "    print(f\"\\n========== {name.upper()} ==========\")\n",
    "\n",
    "    # -------- A. Encodage --------\n",
    "    if name == \"tfidf\":\n",
    "        from joblib import load\n",
    "\n",
    "        vectorizer = load(\"../outputs/full/tfidf_vectorizer.pkl\")\n",
    "        X = vectorizer.transform(texts)\n",
    "\n",
    "    elif name == \"minilm\":\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "\n",
    "        model = SentenceTransformer(spec)\n",
    "        X = model.encode(texts, batch_size=128, show_progress_bar=True)\n",
    "\n",
    "    elif name == \"word2vec\":\n",
    "        from gensim.models import Word2Vec\n",
    "        tok_texts = [t.split() for t in texts]          # tokenise simple\n",
    "        w2v = Word2Vec(sentences=tok_texts,\n",
    "                   vector_size=100, window=5,\n",
    "                   min_count=2, workers=4, epochs=20)\n",
    "        X = np.array([np.mean([w2v.wv[w] for w in sent if w in w2v.wv]\n",
    "                          or np.zeros(100), axis=0) for sent in tok_texts])\n",
    "\n",
    "    elif name == \"doc2vec\":\n",
    "        from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "        tagged = [TaggedDocument(words=t.split(), tags=[i])\n",
    "              for i, t in enumerate(texts)]\n",
    "        d2v = Doc2Vec(tagged, vector_size=100, workers=4, epochs=40)\n",
    "        X = np.array([d2v.infer_vector(t.split()) for t in texts])\n",
    "\n",
    "    elif name == \"glove\":\n",
    "        import gensim.downloader as api\n",
    "        glove = api.load(spec)                     # word-vectors 100 d\n",
    "        X = np.array([np.mean([glove[w] for w in t.split() if w in glove]\n",
    "                          or np.zeros(100), axis=0) for t in texts])\n",
    "\n",
    "\n",
    "    # (placeholders pour les autres embeddings)\n",
    "    else:\n",
    "        print(\">>> À implémenter dans la prochaine étape\")\n",
    "        continue\n",
    "\n",
    "    # -------- B. Split, entraînement, rapport --------\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X, y, test_size=0.20, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    clf = LogisticRegression(max_iter=10_000, n_jobs=-1)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    y_pred = clf.predict(X_val)\n",
    "\n",
    "    print(classification_report(y_val, y_pred, digits=3))\n"
   ],
   "id": "999b4a6bba90fc89",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== TFIDF ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.986     1.000     0.993       275\n",
      "           1      1.000     0.636     0.778        11\n",
      "\n",
      "    accuracy                          0.986       286\n",
      "   macro avg      0.993     0.818     0.885       286\n",
      "weighted avg      0.986     0.986     0.985       286\n",
      "\n",
      "\n",
      "========== MINILM ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 12/12 [06:01<00:00, 30.15s/it]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       275\n",
      "           1      1.000     1.000     1.000        11\n",
      "\n",
      "    accuracy                          1.000       286\n",
      "   macro avg      1.000     1.000     1.000       286\n",
      "weighted avg      1.000     1.000     1.000       286\n",
      "\n",
      "\n",
      "========== WORD2VEC ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     1.000     0.996       275\n",
      "           1      1.000     0.818     0.900        11\n",
      "\n",
      "    accuracy                          0.993       286\n",
      "   macro avg      0.996     0.909     0.948       286\n",
      "weighted avg      0.993     0.993     0.993       286\n",
      "\n",
      "\n",
      "========== DOC2VEC ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.978     0.982     0.980       275\n",
      "           1      0.500     0.455     0.476        11\n",
      "\n",
      "    accuracy                          0.962       286\n",
      "   macro avg      0.739     0.718     0.728       286\n",
      "weighted avg      0.960     0.962     0.961       286\n",
      "\n",
      "\n",
      "========== GLOVE ==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.993     1.000     0.996       275\n",
      "           1      1.000     0.818     0.900        11\n",
      "\n",
      "    accuracy                          0.993       286\n",
      "   macro avg      0.996     0.909     0.948       286\n",
      "weighted avg      0.993     0.993     0.993       286\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-25T17:39:48.329110Z",
     "start_time": "2025-05-25T17:07:36.335186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -- Encode MiniLM (réutilise ton 'model' déjà chargé) --\n",
    "X_minilm = model.encode(texts, batch_size=128, show_progress_bar=True)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_minilm, y, test_size=0.20, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "svm = LinearSVC(class_weight=\"balanced\")\n",
    "svm.fit(X_tr, y_tr)\n",
    "y_pred = svm.predict(X_val)\n",
    "\n",
    "print(classification_report(y_val, y_pred, digits=3))\n"
   ],
   "id": "75b8454a2414c6b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 12/12 [32:11<00:00, 160.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     1.000     1.000       275\n",
      "           1      1.000     1.000     1.000        11\n",
      "\n",
      "    accuracy                          1.000       286\n",
      "   macro avg      1.000     1.000     1.000       286\n",
      "weighted avg      1.000     1.000     1.000       286\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
